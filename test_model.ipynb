{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%matplotlibe` not found.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from sacred import Experiment\n",
    "from argparse import Namespace\n",
    "from torchvision import transforms\n",
    "\n",
    "from pytorchtools import EarlyStopping\n",
    "\n",
    "from analysis import plot_loss\n",
    "from load_data.eye_dataset import EyeDataset, EyeDatasetOverfitCorners, EyeDatasetOverfitCenter\n",
    "import logging\n",
    "import numpy as np\n",
    "from models.fc import FC\n",
    "from models.unet import UNET\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "ex = Experiment('EyeSegnmentation', interactive=True)\n",
    "ex.logger = logger\n",
    "\n",
    "%matplotlibe inline\n",
    "\n",
    "@ex.config\n",
    "def cfg():\n",
    "    data_path = 'data/drive/training'\n",
    "    data_path_training = 'data/drive/training'\n",
    "    data_path_validation = 'data/drive/validation'\n",
    "    data_path_test = 'data/drive/test'\n",
    "    num_epochs = 10000\n",
    "    batch_size = 1\n",
    "    plot_loss = True\n",
    "    checkpoint_path = 'checkpoints/v1'\n",
    "    is_save_model = False\n",
    "    #model_load_path = None\n",
    "    model_load_path = 'checkpoints/v1/20190609-150526'\n",
    "    display_images = True\n",
    "    \n",
    "    \n",
    "@ex.main\n",
    "def main(_run):\n",
    "    args = Namespace(**_run.config)\n",
    "    logger.info(args)\n",
    "\n",
    "    # ------ Michals modification: split train and validation in advance ------ #\n",
    "    # train and validation images should be placed in args.data_path_training and args.data_path_validation\n",
    "    # last 4 images (#37-40) are used as validation\n",
    "    loader_train = EyeDatasetOverfitCenter(args.data_path_training, augment=True, normalization=True)\n",
    "    loader_val = EyeDatasetOverfitCenter(args.data_path_validation, augment=True, normalization=True)\n",
    "    loader_test = EyeDatasetOverfitCenter(args.data_path_test, augment=True, normalization=True)\n",
    "\n",
    "    # loader = EyeDataset(args.data_path, augment=True)\n",
    "    ## training_data = DataLoader(loader, shuffle=True, batch_size=1, sampler=train_sampler)\n",
    "    # training_data, test_data = split_dataset_to_train_and_test(loader, args.batch_size)\n",
    "\n",
    "    training_data = DataLoader(loader_train, batch_size=args.batch_size)\n",
    "    validatoin_data = DataLoader(loader_val, batch_size=args.batch_size)\n",
    "    test_data = DataLoader(loader_test, batch_size=args.batch_size)\n",
    "    # ------------------------------------------------------------------------- #\n",
    "\n",
    "    model = choose_model(args, training_data)\n",
    "    # TEST\n",
    "    print(\"evaluate on training data\")\n",
    "    evaluate_results(args, model, training_data)\n",
    "    print(\"evaluate on validation data\")\n",
    "    evaluate_results(args, model, validatoin_data)\n",
    "    # print(\"evaluate on test data\")\n",
    "    # evaluate_results(args, model, test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
